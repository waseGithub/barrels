{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R96ObTxG13xl"
   },
   "source": [
    "# Data cleaning for online data.\n",
    "All data used in this script is taken from the data lake (/content/gdrive/MyDrive/Barrels/data_lake). --\n",
    "*Location where data is transfered directly from the lab pc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "background_save": true
    },
    "id": "CNuKWfYsukRC"
   },
   "outputs": [],
   "source": [
    "#@title Library import **ignore**\n",
    "%%capture\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')                    \n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np      \n",
    "from google.colab import data_table\n",
    "data_table.enable_dataframe_formatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 27343,
     "status": "ok",
     "timestamp": 1668767150268,
     "user": {
      "displayName": "Intern Wase",
      "userId": "12745124527750154900"
     },
     "user_tz": 0
    },
    "id": "QvE_fDQ7ia9Q"
   },
   "outputs": [],
   "source": [
    "#@title Load and inital clean CSV **arduino** and **RS** data\n",
    "%%capture\n",
    "path2csv = Path(\"/content/gdrive/MyDrive/Barrels/data_lake\")\n",
    "destination_temp_tip = Path('/content/gdrive/MyDrive/Barrels/cleaned/out.csv')\n",
    "destination_power = Path('/content/gdrive/MyDrive/Barrels/cleaned/out.csv')\n",
    "\n",
    "# filepath = Path('folder/subfolder/out.csv')\n",
    "\n",
    "csvlist = path2csv.glob(\"*.csv\")\n",
    "sensor_ls = []\n",
    "power_ls = []\n",
    "\n",
    "for csv in csvlist:\n",
    "  # print(csv)\n",
    "  sen_data = str(csv).find(\"sensor_all\")\n",
    "  power_data = str(csv).find(\"power_data\")\n",
    "\n",
    "  if sen_data == 42:\n",
    "    \n",
    "    # print('tipper and temp data found')\n",
    "    df = pd.read_csv(csv)\n",
    "    df = df.loc[df[\"strt\"] == \"-*\"]\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.set_index(['ID', 'datetime'])\n",
    "    df['Cnt'] = pd.to_numeric(df.Cnt, errors='coerce')\n",
    "    # df['Cnt'] = df['Cnt'].astype(int)\n",
    "    df[\"Tmp1\"] = pd.to_numeric(df[\"Tmp1\"], errors='coerce')\n",
    "    df[\"Tmp2\"] = pd.to_numeric(df[\"Tmp2\"], errors='coerce')\n",
    "    df_temp = df.groupby([pd.Grouper(freq='10T', level='datetime'), pd.Grouper(level='ID')])['Tmp1', 'Tmp2'].mean() \n",
    "    df_count = df.groupby([pd.Grouper(freq='10T', level='datetime'), pd.Grouper(level='ID')])['Cnt'].max()\n",
    "    df = pd.concat([df_temp, df_count], axis=1)   \n",
    "    df.reset_index(inplace = True)\n",
    "    df = df.sort_values(by=['datetime', 'ID'])\n",
    "    df.dropna(inplace=True)\n",
    "    df.set_index(['datetime', 'ID'], inplace=True)\n",
    "    # destination.parent.mkdir(parents=True, exist_ok=True) \n",
    "    sensor_ls.append(df)\n",
    "    # os.remove(csv)\n",
    "\n",
    "  elif power_data == 42:\n",
    "    df_header = pd.read_csv(csv, nrows=14, names=['attribute', 'data'])\n",
    "    colnames = [\"Timestamp\",\"U1[V]\",\"I1[A]\",\"P1[W]\",\"U2[V]\",\"I2[A]\",\"P2[W]\",\"U3[V]\",\"I3[A]\",\"P3[W]\",\"U4[V]\",\"I4[A]\",\"P4[W]\"]\n",
    "    df = pd.read_csv(csv, skiprows=16, names=colnames)\n",
    "\n",
    "    start_time = df_header[df_header['attribute'] == '#Start Time'].data.values[0]\n",
    "    start_date = df_header[df_header['attribute'] == '#Date'].data.values[0]\n",
    "    start_datetime = str(str(start_date) + \" \" + str(start_time))\n",
    "    increment = df_header[df_header['attribute'] == '#Logging Interval[s]'].data.values[0]\n",
    "    increment = int(float(increment))/ 60\n",
    "    count_row = df.shape[0] \n",
    "    duration = increment * (count_row)\n",
    "    end_datetime= pd.to_datetime(start_datetime) + pd.to_timedelta(duration,'m')\n",
    "    # print(duration)\n",
    "    # print(count_row)    \n",
    "    # print(\"start time\", start_datetime)\n",
    "    # print(\"end time\", end_datetime)\n",
    "\n",
    "    ls_datetime_range = pd.date_range(start=start_datetime, periods=count_row, freq='5Min')\n",
    "    df_datetimes = pd.DataFrame(ls_datetime_range, columns=['datetime'])\n",
    "    df = pd.concat([df, df_datetimes], axis=1)\n",
    "    df.set_index('datetime', inplace =True)\n",
    "    tank_1 = df[[\"U1[V]\", \"I1[A]\", \"P1[W]\"]]\n",
    "    tank_1['ID'] = 1\n",
    "    tank_1 = tank_1.rename(columns={'U1[V]': 'V', 'I1[A]': 'A', 'P1[W]': 'P'})\n",
    "    tank_2 = df[[\"U2[V]\", \"I2[A]\", \"P2[W]\"]]\n",
    "    tank_2['ID'] = 2\n",
    "    tank_2 = tank_2.rename(columns={'U2[V]': 'V', 'I2[A]': 'A', 'P2[W]': 'P'})\n",
    "    tank_3 = df[[\"U3[V]\", \"I3[A]\", \"P3[W]\"]]\n",
    "    tank_3['ID'] = 3\n",
    "    tank_3 = tank_3.rename(columns={'U3[V]': 'V', 'I3[A]': 'A', 'P3[W]': 'P'})\n",
    "    tank_4 = df[[\"U4[V]\", \"I4[A]\", \"P4[W]\"]]\n",
    "    tank_4['ID'] = 4\n",
    "    tank_4 = tank_4.rename(columns={'U4[V]': 'V', 'I4[A]': 'A', 'P4[W]': 'P'})\n",
    "\n",
    "    df = pd.concat([tank_1, tank_2, tank_3, tank_4], axis=0) \n",
    "    df.reset_index(inplace=True)\n",
    "    df.set_index(['datetime', 'ID'], inplace=True)\n",
    "    df = df.groupby([pd.Grouper(freq='5T', level='datetime'), pd.Grouper(level='ID')])['V', 'A', 'P'].mean()   \n",
    "    power_ls.append(df)\n",
    "    \n",
    "    # os.remove(csv)\n",
    "  \n",
    "\n",
    "    \n",
    "try:\n",
    "  df_tip_temp = pd.concat(sensor_ls, axis=0)\n",
    "  df_tip_temp['Cnt_delta'] = df_tip_temp['Cnt'].diff(periods = 4)\n",
    "  df_tip_temp['Cnt_delta'] = df_tip_temp['Cnt_delta'][(df_tip_temp[['Cnt_delta']] < 600).all(1)]\n",
    "\n",
    "\n",
    " \n",
    "except ValueError:\n",
    "  pass\n",
    "\n",
    "try:\n",
    "  df_power = pd.concat(power_ls, axis=0)\n",
    "except ValueError:\n",
    "  pass\n",
    "\n",
    "\n",
    "\n",
    "df_tip_temp = df_tip_temp[(df_tip_temp[['Tmp2']] > 0).all(1)]\n",
    "df_tip_temp['Cnt_delta'][df_tip_temp['Cnt_delta'] > 600] = np.nan\n",
    "df_tip_temp = df_tip_temp.loc[df_tip_temp['Tmp1'] < 40] \n",
    "df_tip_temp = df_tip_temp.loc[df_tip_temp['Tmp2'] < 40] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1668767150487,
     "user": {
      "displayName": "Intern Wase",
      "userId": "12745124527750154900"
     },
     "user_tz": 0
    },
    "id": "uI-v6g_Hv7nG"
   },
   "outputs": [],
   "source": [
    "#@title Adjust tipper volumes\n",
    "%%capture\n",
    "df_tip_temp.reset_index(inplace=True)\n",
    "df1x1 = df_tip_temp.loc[df_tip_temp['ID'] == 1]\n",
    "df1x2 = df_tip_temp.loc[df_tip_temp['ID'] == 1]\n",
    "df1x1['volume'] = df1x1[(df1x1['datetime'] <= \"2022-11-02 10:00:00\")]['Cnt_delta'] * 9.63\n",
    "df1x2['volume'] = df1x2[(df1x2['datetime'] > \"2022-11-02 10:00:00\")]['Cnt_delta'] * 31.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df2 = df_tip_temp.loc[df_tip_temp['ID'] == 2]\n",
    "df2['volume'] = df2['Cnt_delta'] * 4.6\n",
    "df3 = df_tip_temp.loc[df_tip_temp['ID'] == 3]\n",
    "df3['volume'] = df3['Cnt_delta'] * 8.4\n",
    "df4 = df_tip_temp.loc[df_tip_temp['ID'] == 4]\n",
    "df4['volume'] = df4['Cnt_delta'] * 9.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_ls = [df1x1, df1x2, df2, df3, df4]\n",
    "df_tip_temp = pd.concat(df_ls, axis=0) \n",
    "df_tip_temp = df_tip_temp.sort_values(by=['datetime', 'ID'])\n",
    "df_tip_temp.set_index(['datetime', 'ID'], inplace=True)\n",
    "\n",
    "display(df_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35154,
     "status": "ok",
     "timestamp": 1668767185638,
     "user": {
      "displayName": "Intern Wase",
      "userId": "12745124527750154900"
     },
     "user_tz": 0
    },
    "id": "WEWPVntN2GD4",
    "outputId": "1f45859e-d09a-429e-e679-cce5d9cb9f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates includedtipper and tempdata:\n",
      "['2022-10-14', '2022-10-25', '2022-10-26', '2022-10-27', '2022-10-28', '2022-10-29', '2022-10-30', '2022-10-31', '2022-11-01', '2022-11-02', '2022-11-03', '2022-11-04', '2022-11-05', '2022-11-06', '2022-11-07', '2022-11-08', '2022-11-09', '2022-11-10', '2022-11-11', '2022-11-12', '2022-11-13', '2022-11-14', '2022-11-15', '2022-11-16', '2022-11-17', '2022-11-18']\n",
      "Dates includedpower datadata:\n",
      "['2022-10-17', '2022-10-18', '2022-10-19', '2022-10-20', '2022-10-21', '2022-10-22', '2022-10-23', '2022-10-24', '2022-10-25', '2022-10-26', '2022-10-27', '2022-10-28', '2022-10-29', '2022-10-30', '2022-10-31', '2022-11-01', '2022-11-02', '2022-11-03', '2022-11-04', '2022-11-05', '2022-11-06', '2022-11-07', '2022-11-08', '2022-11-09', '2022-11-10', '2022-11-11', '2022-11-12', '2022-11-13', '2022-11-14', '2022-11-15', '2022-11-16', '2022-11-17']\n"
     ]
    }
   ],
   "source": [
    "#@title Add cleaned data to new location **Power data** -- /content/gdrive/MyDrive/Barrels/cleaned_power **Tipper and temperature** -- /content/gdrive/MyDrive/Barrels/cleaned_tip_temp\n",
    "\n",
    "\n",
    "def move_to_cleaned(name, df, loc):\n",
    "  df.reset_index(inplace=True)\n",
    "  df['date'] = df['datetime'].dt.date\n",
    "  df['date'] = df.date.astype(str)\n",
    "  df.set_index('date', inplace =True)\n",
    "  df = df.round(3)\n",
    "  df.dropna(inplace=True)\n",
    "  df = df.loc[df['ID'].isin([1,2,3,4])]\n",
    "  d_list = []\n",
    "  for d in df.index:\n",
    "    d_list.append(d)\n",
    "  res = []\n",
    "  [res.append(x) for x in d_list if x not in res]\n",
    "  print('Dates included' + name + 'data:')\n",
    "  print(res)\n",
    "  df.reset_index(inplace = True)\n",
    "  \n",
    "\n",
    "\n",
    "  for i in np.arange(len(res)):\n",
    "    x = df[(df.date == res[i])]\n",
    "    \n",
    "    filepath = Path('/content/gdrive/MyDrive/Barrels/'+ loc + res[i]+ '.csv') \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    x.to_csv(filepath, index=False, mode='a')\n",
    "    x2 = pd.read_csv(filepath)\n",
    "    try:\n",
    "      x2 = x2.drop_duplicates(subset=['datetime', 'ID'], keep='last')\n",
    "    except KeyError:\n",
    "      pass\n",
    "    try:\n",
    "      x2 = x2[x2.date != 'date']\n",
    "    except AttributeError:\n",
    "      pass\n",
    "    x2.to_csv(filepath, index=False, mode='w')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "move_to_cleaned(\"tipper and temp\", df_tip_temp, \"cleaned_tip_temp/\")\n",
    "\n",
    "try:\n",
    "  move_to_cleaned(\"power data\", df_power, \"cleaned_power/\")\n",
    "except NameError:\n",
    "  pass\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
